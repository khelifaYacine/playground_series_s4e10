{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84894,"databundleVersionId":9709193,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/khelifayacine/playground-series-saison-4-pisode-10?scriptVersionId=200148783\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploration des données :","metadata":{}},{"cell_type":"code","source":"# Importation des packages\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import roc_auc_score\n\n# Package modélisation \nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importation des données \ndf_train = pd.read_csv(\"/kaggle/input/playground-series-s4e10/train.csv\")\ndf_test = pd.read_csv (\"/kaggle/input/playground-series-s4e10/test.csv\")\ndf_train.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Description des colonnes :\n- id : Identifiant unique pour chaque observation.\n- person_age : Âge du demandeur de prêt.\n- person_income : Revenu annuel du demandeur.\n- person_home_ownership : Statut de propriété du logement (par exemple : RENT, OWN, MORTGAGE).\n- person_emp_length : Nombre d'années d'emploi du demandeur.\n- loan_intent : Raison du prêt (par exemple : EDUCATION, MEDICAL, VENTURE).\n- loan_grade : Classement du prêt attribué (par exemple : A, B, C).\n- loan_amnt : Montant demandé pour le prêt.\n- loan_int_rate : Taux d'intérêt du prêt.\n- loan_percent_income : Proportion du revenu du demandeur par rapport au montant du prêt.\n- cb_person_default_on_file : Indicateur de défaut de paiement dans l'historique de crédit du demandeur (Y/N).\n- cb_person_cred_hist_length : Durée de l'historique de crédit du demandeur (en années).\n- loan_status : Statut du prêt (0 pour refusé, 1 pour approuvé).","metadata":{}},{"cell_type":"code","source":"df_test.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Analyse de valeurs manquantes\ndf_train.isna().sum()#aucune valeure manquante !","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Analyse des statistiques descriptives :\ndf_train.describe()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.duplicated().sum()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DataViz","metadata":{}},{"cell_type":"markdown","source":"1. Visualisation de la distribution de la cible (loan_status) :","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nsns.countplot(data=df_train, x='loan_status')\nplt.title('Distribution de la variable cible (loan_status)')\nplt.xlabel('Loan Status (0: Non-Approved, 1: Approved)')\nplt.ylabel('Count')\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Vérification des corrélations entre les variables numériques :","metadata":{}},{"cell_type":"code","source":"# Sélectionner les colonnes numériques uniquement\nnumerical_cols = df_train.select_dtypes(include=['int64', 'float64'])\n\n# Calculer la matrice de corrélation\ncorr_matrix = numerical_cols.corr()\n\n# Afficher la matrice de corrélation\nplt.figure(figsize=(10, 6))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\nplt.title('Matrice de corrélation entre les variables numériques')\nplt.show()\n\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Étape 2 : Visualisation des Relations","metadata":{}},{"cell_type":"markdown","source":"3) Visualisation des relations entre les caractéristiques et la cible :","metadata":{}},{"cell_type":"markdown","source":"Age et Loan Status :","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nsns.boxplot(data=df_train, x='loan_status', y='person_age')\nplt.title('Âge des demandeurs selon le statut du prêt')\nplt.xlabel('Loan Status')\nplt.ylabel('Age')\nplt.xticks([0, 1], ['Non-Approved', 'Approved'])\nplt.show()\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Revenu et Loan Status :","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nsns.boxplot(data=df_train, x='loan_status', y='person_income')\nplt.title('Revenu des demandeurs selon le statut du prêt')\nplt.xlabel('Loan Status')\nplt.ylabel('Income')\nplt.xticks([0, 1], ['Non-Approved', 'Approved'])\nplt.show()\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4) Visualisation des catégories :","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.countplot(data=df_train, x='person_home_ownership', hue='loan_status')\nplt.title('Propriétés de logement selon le statut du prêt')\nplt.xlabel('Home Ownership')\nplt.ylabel('Count')\nplt.legend(title='Loan Status', loc='upper right', labels=['Non-Approved', 'Approved'])\nplt.show()\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsns.boxplot(df_train['person_income'])\nplt.title('Distribution du revenu')\nplt.show()\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualisation des distributions avec KDE (Estimation de Densité Noyau) :","metadata":{}},{"cell_type":"code","source":"sns.kdeplot(df_train, x='person_income',hue='loan_status')\nplt.title('Distribution du revenu par statut du prêt')\nplt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Statistiques sur les outliers : \n- Calculer le nombre d'observations qui sont considérées comme des outliers. Cela peut être fait en utilisant l'écart interquartile (IQR) pour définir des seuils.","metadata":{}},{"cell_type":"code","source":"Q1 = df_train['person_income'].quantile(0.25)\nQ3 = df_train['person_income'].quantile(0.75)\nIQR = Q3 - Q1\n\noutliers = df_train[(df_train['person_income'] < (Q1 - 1.5 * IQR)) | (df_train['person_income'] > (Q3 + 1.5 * IQR))]\nprint(f\"Nombre d'outliers dans person_income : {len(outliers)}\")\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(df_train[df_train['person_income'] < (Q3 + 1.5 * IQR)]['person_income'])\nplt.title('Distribution du revenu sans outliers')\nplt.show()\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Distribution log-transformée :\n- Si les valeurs extrêmes sont légitimes et qu'il est nécessaire de travailler avec ces données, appliquer une transformation logarithmique peut aider à normaliser la distribution.","metadata":{}},{"cell_type":"code","source":"df_train['log_person_income'] = np.log1p(df_train['person_income'])\nsns.histplot(df_train['log_person_income'], kde=True)\nplt.title('Distribution du revenu (log-transformée)')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Résumé des Étapes d'EDA :\n- Visualisation de la distribution de la variable cible pour voir la balance des classes.\n- Analyse descriptive pour comprendre les caractéristiques des données.\n- Corrélations pour identifier les relations entre les variables.\n- Visualisation des relations entre les caractéristiques et la cible pour mieux comprendre l'impact de chaque variable.","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing de données ","metadata":{}},{"cell_type":"markdown","source":"Encodage des variables df_train","metadata":{}},{"cell_type":"code","source":"label_encoder = LabelEncoder()\ndf_train['person_home_ownership'] = label_encoder.fit_transform(df_train['person_home_ownership'])\ndf_train['loan_intent'] = label_encoder.fit_transform(df_train['loan_intent'])\ndf_train['loan_grade'] = label_encoder.fit_transform(df_train['loan_grade'])\ndf_train['cb_person_default_on_file'] = label_encoder.fit_transform(df_train['cb_person_default_on_file'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Encodage du dataset df_test","metadata":{}},{"cell_type":"code","source":"df_test['person_home_ownership'] = label_encoder.fit_transform(df_test['person_home_ownership'])\ndf_test['loan_intent'] = label_encoder.fit_transform(df_test['loan_intent'])\ndf_test['loan_grade'] = label_encoder.fit_transform(df_test['loan_grade'])\ndf_test['cb_person_default_on_file'] = label_encoder.fit_transform(df_test['cb_person_default_on_file'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vérifier si les colonnes de df_train (sans la cible) et df_test correspondent\ntrain_columns = df_train.drop(columns=['loan_status']).columns\ntest_columns = df_test.columns\n\n# Vérification des différences\nif set(train_columns) != set(test_columns):\n    print(\"Les colonnes entre df_train et df_test ne correspondent pas.\")\n    print(\"Colonnes manquantes dans df_test :\", set(train_columns) - set(test_columns))\n    print(\"Colonnes supplémentaires dans df_test :\", set(test_columns) - set(train_columns))\nelse:\n    print(\"Les colonnes correspondent.\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5. Séparation des données en train/test (Validation) :\n\nAvant d'entraîner ton modèle, il est nécessaire de séparer notre dataset en données d'entraînement et de test pour éviter le surapprentissage et tester la généralisation du modèle.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Séparation des données (80% train, 20% test)\nX = df_train.drop('loan_status', axis=1)\ny = df_train['loan_status']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modélisation ","metadata":{}},{"cell_type":"markdown","source":"1. Choix du modèle :\n\nPlusieurs modèles peuvent être testés, par exemple :\n- Régression Logistique\n- Arbres de décision\n- Random Forest\n- Gradient Boosting\n- XGBoost\n- LightGBM","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\n# Logistic Regression\nmodel_log_reg = LogisticRegression(max_iter=1000)\nmodel_log_reg.fit(X, y)\nlog_reg_acc = cross_val_score(model_log_reg, X, y, cv=5, scoring='accuracy').mean()\nlog_reg_roc_auc = cross_val_score(model_log_reg, X, y, cv=5, scoring='roc_auc').mean()\n\nprint(f\"Logistic Regression - Accuracy: {log_reg_acc:.4f}, ROC AUC (CV 5 folds): {log_reg_roc_auc:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Forest\nmodel_rf = RandomForestClassifier()\nmodel_rf.fit(X, y)\nrf_acc = cross_val_score(model_rf, X, y, cv=5, scoring='accuracy').mean()\nrf_roc_auc = cross_val_score(model_rf, X, y, cv=5, scoring='roc_auc').mean()\n\nprint(f\"Random Forest - Accuracy: {rf_acc:.4f}, ROC AUC (CV 5 folds): {rf_roc_auc:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# KNN\nmodel_knn = KNeighborsClassifier()\nmodel_knn.fit(X, y)\nknn_acc = cross_val_score(model_knn, X, y, cv=5, scoring='accuracy').mean()\nknn_roc_auc = cross_val_score(model_knn, X, y, cv=5, scoring='roc_auc').mean()\n\nprint(f\"KNN - Accuracy: {knn_acc:.4f}, ROC AUC (CV 5 folds): {knn_roc_auc:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decision Tree\nmodel_dt = DecisionTreeClassifier()\nmodel_dt.fit(X, y)\ndt_acc = cross_val_score(model_dt, X, y, cv=5, scoring='accuracy').mean()\ndt_roc_auc = cross_val_score(model_dt, X, y, cv=5, scoring='roc_auc').mean()\n\nprint(f\"Decision Tree - Accuracy: {dt_acc:.4f}, ROC AUC (CV 5 folds): {dt_roc_auc:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost\nmodel_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\nmodel_xgb.fit(X, y)\nxgb_acc = cross_val_score(model_xgb, X, y, cv=5, scoring='accuracy').mean()\nxgb_roc_auc = cross_val_score(model_xgb, X, y, cv=5, scoring='roc_auc').mean()\n\nprint(f\"XGBoost - Accuracy: {xgb_acc:.4f}, ROC AUC (CV 5 folds): {xgb_roc_auc:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Optimiser Tous les Modèles","metadata":{}},{"cell_type":"code","source":"# Afficher l'importance des variables pour la régression logistique\nlogistic_model = LogisticRegression(max_iter=1000)\nlogistic_model.fit(X, y)\n\n# Importance des variables à partir des coefficients\nimportances = np.abs(logistic_model.coef_[0])\nindices = np.argsort(importances)[::-1]\n\n# Tracer l'importance des variables\nplt.figure(figsize=(10, 6))\nplt.title(\"Importance des Variables - Logistic Regression\")\nplt.bar(range(X.shape[1]), importances[indices], align=\"center\")\nplt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\nplt.xlim([-1, X.shape[1]])\nplt.ylabel(\"Coefficient\")\nplt.xlabel(\"Variables\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Afficher l'importance des variables pour Random Forest\nrandom_forest_model = RandomForestClassifier()\nrandom_forest_model.fit(X, y)\n\n# Importance des variables\nimportances = random_forest_model.feature_importances_\nindices = np.argsort(importances)[::-1]\n\n# Tracer l'importance des variables\nplt.figure(figsize=(10, 6))\nplt.title(\"Importance des Variables - Random Forest\")\nplt.bar(range(X.shape[1]), importances[indices], align=\"center\")\nplt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\nplt.xlim([-1, X.shape[1]])\nplt.ylabel(\"Importance\")\nplt.xlabel(\"Variables\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Afficher l'importance des variables pour Decision Tree\ndecision_tree_model = DecisionTreeClassifier()\ndecision_tree_model.fit(X, y)\n\n# Importance des variables\nimportances = decision_tree_model.feature_importances_\nindices = np.argsort(importances)[::-1]\n\n# Tracer l'importance des variables\nplt.figure(figsize=(10, 6))\nplt.title(\"Importance des Variables - Decision Tree\")\nplt.bar(range(X.shape[1]), importances[indices], align=\"center\")\nplt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\nplt.xlim([-1, X.shape[1]])\nplt.ylabel(\"Importance\")\nplt.xlabel(\"Variables\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Afficher l'importance des variables pour XGBoost\nxgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\nxgb_model.fit(X, y)\n\n# Importance des variables\nimportances = xgb_model.feature_importances_\nindices = np.argsort(importances)[::-1]\n\n# Tracer l'importance des variables\nplt.figure(figsize=(10, 6))\nplt.title(\"Importance des Variables - XGBoost\")\nplt.bar(range(X.shape[1]), importances[indices], align=\"center\")\nplt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\nplt.xlim([-1, X.shape[1]])\nplt.ylabel(\"Importance\")\nplt.xlabel(\"Variables\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion sur le Choix du Modèle\nChoisir Random Forest pour les prédictions sur df_test est judicieux, notamment parce que ce modèle excelle dans la gestion de datasets comportant de nombreuses variables, tout en offrant des performances solides grâce à son approche basée sur des arbres décisionnels multiples. De plus, il est capable de capter des relations complexes et des interactions entre les variables sans nécessiter de transformation extensive des données.\n","metadata":{}},{"cell_type":"markdown","source":"# Prediction sur le Test_csv","metadata":{}},{"cell_type":"markdown","source":"1. Prédiction RandomForest","metadata":{}},{"cell_type":"code","source":"#  RandomForestClassifier \nbest_model = RandomForestClassifier()\n\n# Entraînement du modèle sur df_train\nbest_model.fit(X_train, y_train)\n\n# Faire des prédictions sur df_test\ny_test_pred = best_model.predict(df_test)\n\n# Si le modèle supporte les probabilités, obtenir les probabilités:\ny_test_pred_proba = best_model.predict_proba(df_test)[:, 1]\n\n# Créer un fichier de soumission\nsubmission = pd.DataFrame({\n    'id': df_test['id'],  \n    'loan_status': y_test_pred  # Ou utiliser y_test_pred_proba si tu veux soumettre des probabilités\n})\n\n# Sauvegarder le fichier de soumission\nchemin_fichier = '/kaggle/working/submission.csv'\nsubmission.to_csv(chemin_fichier, index=False)\nprint(f\"Fichier de soumission créé avec succès dans {chemin_fichier}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Afficher les 20 premières lignes des prédictions\nresult = pd.DataFrame({\n    'id': df_test['id'],\n    'loan_status_pred': y_test_pred\n})\nprint(result.head(20))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prédictions sur df_test\ny_test_pred = best_model.predict(df_test)\n\n# Affichage des résultats\nresult_counts = pd.Series(y_test_pred).value_counts()\n\n# Créer un graphique à barres\nplt.figure(figsize=(8, 5))\nsns.barplot(x=result_counts.index, y=result_counts.values, palette='viridis')\n\n# Ajouter les labels et le titre\nplt.title('Prédictions de Random Forest sur df_test')\nplt.xlabel('Loan Status')\nplt.ylabel('Count')\nplt.xticks(ticks=result_counts.index, labels=result_counts.index, rotation=0)\n\n# Ajouter le pourcentage au-dessus de chaque barre\ntotal_count = result_counts.sum()\nfor index, value in enumerate(result_counts):\n    percentage = (value / total_count) * 100\n    plt.text(index, value, f'{percentage:.1f}%', ha='center', va='bottom')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. Prédiction XGBOOST","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n# Entraîner XGBoost sur df_train\nbest_model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n\n# Entraînement du modèle sur les données d'entraînement\nbest_model_xgb.fit(X_train, y_train)\n\n# Faire des prédictions sur df_test\ny_test_pred_xgb = best_model_xgb.predict(df_test)\n\n# Si tu veux aussi les probabilités :\ny_test_pred_proba_xgb = best_model_xgb.predict_proba(df_test)[:, 1]\n\n# Créer un fichier de soumission pour XGBoost\nsubmission_xgb = pd.DataFrame({\n    'id': df_test['id'],  \n    'loan_status': y_test_pred_xgb\n})\n\n# Sauvegarder le fichier de soumission en CSV\nsubmission_xgb.to_csv('submission_XGBoost.csv', index=False)\n\nprint(\"Fichier de soumission XGBoost créé avec succès.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Afficher les 20 premières lignes des prédictions XGBoost\nresult_xgb = pd.DataFrame({\n    'id': df_test['id'],\n    'loan_status_pred': y_test_pred_xgb\n})\nprint(result_xgb.head(20))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Créer un DataFrame pour résumer les prédictions XGBoost\npredictions_summary_xgb = result_xgb['loan_status_pred'].value_counts()\n\n# Calculer les pourcentages pour chaque classe\npercentages = predictions_summary_xgb / predictions_summary_xgb.sum() * 100\n\n# Afficher les valeurs des prédictions\nprint(predictions_summary_xgb)\n\n# Créer un graphique à barres pour XGBoost\nax = predictions_summary_xgb.plot(kind='bar', color=['lightgreen', 'orange'])\n\n# Ajouter les pourcentages ou les valeurs au-dessus des barres\nfor i in ax.containers:\n    ax.bar_label(i, labels=[f'{val:.1f}%' for val in percentages], label_type='edge')\n\n# Ajouter les titres et étiquettes\nplt.title('Répartition des prédictions avec XGBoost - Prêt accepté vs rejeté')\nplt.xlabel('Statut du prêt (0 = rejeté, 1 = accepté)')\nplt.ylabel('Nombre de prédictions')\nplt.xticks(rotation=0)\n\n# Afficher le graphique\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}